{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "Global:\n",
    "\n",
    "Train:\n",
    "  dataset:\n",
    "    transforms:\n",
    "      - DecodeImage: # load image\n",
    "          img_mode: RGB\n",
    "          channel_first: False\n",
    "      - VQATokenLabelEncode: # Class handling label\n",
    "          contains_re: False\n",
    "          algorithm: Bert\n",
    "          class_path: train_data/XFUND/class_list_xfun.txt\n",
    "          use_textline_bbox_info: &use_textline_bbox_info True\n",
    "          order_method: \"tb-yx\" # one of [None, \"tb-yx\"]\n",
    "      - VQATokenPad:\n",
    "          max_seq_len: &max_seq_len 512\n",
    "          return_attention_mask: True\n",
    "      - VQASerTokenChunk:\n",
    "          max_seq_len: 512\n",
    "      - Resize:\n",
    "          size: [224,224]\n",
    "      - NormalizeImage:\n",
    "          scale: 1\n",
    "          mean: [ 123.675, 116.28, 103.53 ]\n",
    "          std: [ 58.395, 57.12, 57.375 ]\n",
    "          order: 'hwc'\n",
    "      - ToCHWImage:\n",
    "      - KeepKeys:\n",
    "          keep_keys: [ 'input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'image', 'labels'] # dataloader will return list in this order\n",
    "\"\"\"\n",
    "\n",
    "import yaml\n",
    "\n",
    "config = yaml.load(config, Loader=yaml.FullLoader)\n",
    "dataset_config = config['Train']['dataset']\n",
    "global_config = config['Global']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "产生 batch 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-16 08:33:32,661] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.bert.tokenizer.BertTokenizer'> to load 'bert-base-chinese'.\u001b[0m\n",
      "\u001b[32m[2022-12-16 08:33:32,664] [    INFO]\u001b[0m - Already cached /mnt/sda/kaihong/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-12-16 08:33:32,676] [    INFO]\u001b[0m - tokenizer config file saved in /mnt/sda/kaihong/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-12-16 08:33:32,677] [    INFO]\u001b[0m - Special tokens file saved in /mnt/sda/kaihong/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from ppocr.data.imaug import create_operators, transform\n",
    "import paddle\n",
    "\n",
    "data_dir = \"train_data/XFUND/zh_train/image\"\n",
    "label_file = \"train_data/XFUND/zh_train/train.json\"\n",
    "with open(label_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "line = lines[1].strip()\n",
    "file_name, label = line.split('\\t')\n",
    "img_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "data = {'img_path': img_path, 'label': label}\n",
    "with open(data['img_path'], 'rb') as f:\n",
    "    img = f.read()\n",
    "    data['image'] = img\n",
    "\n",
    "ops = create_operators(dataset_config['transforms'], global_config)\n",
    "\n",
    "outs = transform(data, ops)\n",
    "outs = [paddle.to_tensor(out, place='cpu') for out in outs]\n",
    "batch = [paddle.unsqueeze(out, axis=0) for out in outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of outs: <class 'list'>\n",
      "len of outs: 6\n",
      "shape of input_ids: [1, 512]\n",
      "shape of bbox: [1, 512, 4]\n",
      "shape of attention_mask: [1, 512]\n",
      "shape of token_type_ids: [1, 512]\n",
      "shape of image: [1, 3, 224, 224]\n",
      "shape of labels: [1, 512]\n"
     ]
    }
   ],
   "source": [
    "print(f\"type of outs: {type(batch)}\")\n",
    "print(f\"len of outs: {len(batch)}\")\n",
    "# keep_keys: [ 'input_ids', 'bbox', 'attention_mask',\n",
    "# 'token_type_ids', 'image', 'labels']\n",
    "print(f\"shape of input_ids: {batch[0].shape}\")\n",
    "print(f\"shape of bbox: {batch[1].shape}\")\n",
    "print(f\"shape of attention_mask: {batch[2].shape}\")\n",
    "print(f\"shape of token_type_ids: {batch[3].shape}\")\n",
    "print(f\"shape of image: {batch[4].shape}\")\n",
    "print(f\"shape of labels: {batch[5].shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizer 使用实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-16 08:33:36,554] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.bert.tokenizer.BertTokenizer'> to load 'bert-base-chinese'.\u001b[0m\n",
      "\u001b[32m[2022-12-16 08:33:36,557] [    INFO]\u001b[0m - Already cached /mnt/sda/kaihong/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-12-16 08:33:36,590] [    INFO]\u001b[0m - tokenizer config file saved in /mnt/sda/kaihong/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-12-16 08:33:36,592] [    INFO]\u001b[0m - Special tokens file saved in /mnt/sda/kaihong/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中 国 人 体 器 官 捐 献 编 号 : [UNK] [UNK] 中 国 人 体 器 官 捐 献 志 愿 登 记 表 在 志 愿 登 记 前, 请 仔 细 阅 读 以 下 内 容 : 1. 人 体 器 官 捐 献 遵 循 [UNK] 自 愿 、 无 偿 [UNK] 的 原 则 。 2. 捐 献 发 生 在 逝 世 之 后, 不 会 影 响 对 您 的 抢 救 和 治 疗 。 3. 最 终 能 否 实 现 捐 献, 需 经 医 学 评 估 并 尊 重 亲 属 的 意 见 。 4. 请 将 捐 献 意 愿 告 知 家 人, 获 得 家 人 的 理 解 和 支 持 。 5. 如 果 捐 献 意 愿 发 生 改 变, 可 以 随 时 变 更 或 撤 销 。 我 具 备 完 全 民 事 行 为 能 力, 已 阅 读 并 知 悉 上 述 内 容, 自 愿 做 如 下 登 记 : 本 人 基 本 信 息 : 姓 名 : ( 身 份 证 / 护 照 ) 号 码 : 210422198210034379 任 星 二 联 系 电 话 : 18655212648 电 子 邮 箱 : 36214515 @ qq. com 登 记 地 : 辽 宁 省 （ 区 / 市 ） 抚 顺 市 （ 州 ） 县 （ 市 / 区 ） 我 志 愿 捐 献 : 器 官 [UNK] ( 眼 角 膜 □ 其 他 组 织 □ 遗 体 □ ) [UNK] 同 意 上 述 所 捐 用 于 临 床 医 疗 、 医 学 教 学 和 科 学 研 究 。 志 愿 登 记 者 签 名 : 任 星 二 2020 年 3 月 15 日 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"layoutxlm-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "input_ids = batch[0][0].numpy().tolist()\n",
    "print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-16 08:33:39,429] [    INFO]\u001b[0m - Already cached /mnt/sda/kaihong/.paddlenlp/models/bert-base-chinese/bert-base-chinese.pdparams\u001b[0m\n",
      "W1216 08:33:39.433658 497045 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.8, Runtime API Version: 11.7\n",
      "W1216 08:33:39.446753 497045 gpu_resources.cc:91] device: 0, cuDNN Version: 8.5.\n",
      "\u001b[32m[2022-12-16 08:33:45,093] [    INFO]\u001b[0m - Weights from pretrained model not used in BertModel: ['cls.predictions.decoder_weight', 'cls.predictions.decoder_bias', 'cls.predictions.transform.weight', 'cls.predictions.transform.bias', 'cls.predictions.layer_norm.weight', 'cls.predictions.layer_norm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ppocr.modeling.architectures import build_model\n",
    "from ppocr.modeling.backbones import build_backbone\n",
    "\n",
    "config = {\n",
    "    'model_type': 'kie',\n",
    "    'Transform': None,\n",
    "    'Backbone': {\n",
    "        'name': 'BertForSer',\n",
    "        'pretrained': True,\n",
    "        'checkpoints': None,\n",
    "        'mode': 'base',\n",
    "        'num_classes': 7\n",
    "    }\n",
    "}\n",
    "\n",
    "model = build_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of preds: <class 'dict'>\n",
      "len of preds: 1\n",
      "type of preds: <class 'dict'>\n",
      "shape of preds['backbone_out']: [1, 512, 7]\n"
     ]
    }
   ],
   "source": [
    "preds = model(batch)\n",
    "\n",
    "print(f\"type of preds: {type(preds)}\")\n",
    "print(f\"len of preds: {len(preds)}\")\n",
    "print(f\"type of preds: {type(preds)}\")\n",
    "print(f\"shape of preds['backbone_out']: {preds['backbone_out'].shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of post_result: 2\n"
     ]
    }
   ],
   "source": [
    "from ppocr.postprocess import build_post_process\n",
    "\n",
    "config = {\n",
    "    \"name\": \"VQASerTokenLayoutLMPostProcess\",\n",
    "    \"class_path\": \"train_data/XFUND/class_list_xfun.txt\"\n",
    "}\n",
    "\n",
    "batch_numpy = [out.numpy() for out in batch]\n",
    "post_process_class = build_post_process(config, global_config)\n",
    "post_result = post_process_class(preds['backbone_out'], batch_numpy)\n",
    "print(f\"len of post_result: {len(post_result)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.0, 'recall': 0.0, 'hmean': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from ppocr.metrics import build_metric\n",
    "\n",
    "config = {\n",
    "    \"name\": \"VQASerTokenMetric\",\n",
    "    \"main_indicator\": \"hmean\",\n",
    "}\n",
    "\n",
    "eval_class = build_metric(config)\n",
    "eval_class(post_result, batch)\n",
    "metric = eval_class.get_metric()\n",
    "print(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "074329d52fc9efe72706b024b6721c6dc35ca1ef98bf3876eecafc902268d71c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
