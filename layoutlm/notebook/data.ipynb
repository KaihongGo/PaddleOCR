{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集划分\n",
    "\n",
    "划分比例 8: 2，将XFUND数据集与自己构建的数据集合并，划分训练集和验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question', 'other', 'header', 'answer'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "label_path = \"train_data/union/label.json\"\n",
    "with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "# shuffle, split the data into train and test, 8:2\n",
    "import random\n",
    "\n",
    "random.shuffle(lines)\n",
    "train_lines = lines[:int(len(lines) * 0.8)]\n",
    "val_lines = lines[int(len(lines) * 0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集统计，统计各个实体数量\n",
    "\n",
    "ocr_info\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"transcription\": doc[\"text\"],\n",
    "    \"label\": doc[\"label\"],\n",
    "    \"points\": points,\n",
    "    \"id\": doc[\"id\"],\n",
    "    \"linking\": doc[\"linking\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dict: {'header': 250, 'question': 4257, 'answer': 5318, 'other': 1914}\n",
      "val_dict: {'header': 71, 'question': 1022, 'answer': 1321, 'other': 456}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"train_data/union/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train_lines = f.readlines()\n",
    "with open(\"train_data/union/val.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    val_lines = f.readlines()\n",
    "\n",
    "train_dict = {}\n",
    "for line in train_lines:\n",
    "    image, ocr_infos = line.strip().split(\"\\t\")\n",
    "    ocr_infos = json.loads(ocr_infos)\n",
    "    for ocr_info in ocr_infos:\n",
    "        label = ocr_info[\"label\"]\n",
    "        train_dict[label] = train_dict.get(label, 0) + 1\n",
    "val_dict = {}\n",
    "for line in val_lines:\n",
    "    image, ocr_infos = line.strip().split(\"\\t\")\n",
    "    ocr_infos = json.loads(ocr_infos)\n",
    "    for ocr_info in ocr_infos:\n",
    "        label = ocr_info[\"label\"]\n",
    "        val_dict[label] = val_dict.get(label, 0) + 1\n",
    "        \n",
    "print(f\"train_dict: {train_dict}\")\n",
    "print(f\"val_dict: {val_dict}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('paddle-ser')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "950fc1bb16e82bb0f5257bb28262b1465fdaab7a1bbf6752f2772d9b7b54f019"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
