{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "Global:\n",
    "\n",
    "Train:\n",
    "  dataset:\n",
    "    transforms:\n",
    "      - DecodeImage: # load image\n",
    "          img_mode: RGB\n",
    "          channel_first: False\n",
    "      - VQATokenLabelEncode: # Class handling label\n",
    "          contains_re: True\n",
    "          algorithm: \"Bert\"\n",
    "          class_path: train_data/XFUND/class_list_xfun.txt\n",
    "          use_textline_bbox_info: True\n",
    "          order_method: \"tb-yx\"\n",
    "      - VQATokenPad:\n",
    "          max_seq_len: 512\n",
    "          return_attention_mask: True\n",
    "      - VQAReTokenRelation:\n",
    "      - VQAReTokenChunk:\n",
    "          max_seq_len: 512\n",
    "      - TensorizeEntitiesRelations:\n",
    "      - Resize:\n",
    "          size: [224,224]\n",
    "      - NormalizeImage:\n",
    "          scale: 1\n",
    "          mean: [ 123.675, 116.28, 103.53 ]\n",
    "          std: [ 58.395, 57.12, 57.375 ]\n",
    "          order: 'hwc'\n",
    "      - ToCHWImage:\n",
    "      - KeepKeys:\n",
    "          keep_keys: [ 'input_ids', 'bbox','attention_mask', 'token_type_ids', 'entities', 'relations']\n",
    "\"\"\"\n",
    "\n",
    "import yaml\n",
    "\n",
    "config = yaml.load(config, Loader=yaml.FullLoader)\n",
    "dataset_config = config['Train']['dataset']\n",
    "global_config = config['Global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-15 00:59:02,788] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.bert.tokenizer.BertTokenizer'> to load 'bert-base-chinese'.\u001b[0m\n",
      "\u001b[32m[2022-12-15 00:59:02,788] [    INFO]\u001b[0m - Already cached /home/kaihong/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-12-15 00:59:02,797] [    INFO]\u001b[0m - tokenizer config file saved in /home/kaihong/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-12-15 00:59:02,797] [    INFO]\u001b[0m - Special tokens file saved in /home/kaihong/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from ppocr.data.imaug import create_operators, transform\n",
    "import paddle\n",
    "\n",
    "data_dir = \"train_data/XFUND/zh_train/image\"\n",
    "label_file = \"train_data/XFUND/zh_train/train.json\"\n",
    "with open(label_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "line = lines[1].strip()\n",
    "file_name, label = line.split('\\t')\n",
    "img_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "data = {'img_path': img_path, 'label': label}\n",
    "with open(data['img_path'], 'rb') as f:\n",
    "    img = f.read()\n",
    "    data['image'] = img\n",
    "\n",
    "ops = create_operators(dataset_config['transforms'], global_config)\n",
    "\n",
    "outs = transform(data, ops)\n",
    "outs = [paddle.to_tensor(out, place='cpu') for out in outs]\n",
    "batch = [paddle.unsqueeze(out, axis=0) for out in outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of outs: <class 'list'>\n",
      "len of outs: 6\n",
      "shape of input_ids: [1, 512]\n",
      "shape of bbox: [1, 512, 4]\n",
      "shape of attention_mask: [1, 512]\n",
      "shape of token_type_ids: [1, 512]\n",
      "shape of entities: [1, 513, 3]\n",
      "shape of relations: [1, 262145, 2]\n"
     ]
    }
   ],
   "source": [
    "print(f\"type of outs: {type(batch)}\")\n",
    "print(f\"len of outs: {len(batch)}\")\n",
    "\n",
    "print(f\"shape of input_ids: {batch[0].shape}\")\n",
    "print(f\"shape of bbox: {batch[1].shape}\")\n",
    "print(f\"shape of attention_mask: {batch[2].shape}\")\n",
    "print(f\"shape of token_type_ids: {batch[3].shape}\")\n",
    "print(f\"shape of entities: {batch[4].shape}\")\n",
    "print(f\"shape of relations: {batch[5].shape}\")\n",
    "\n",
    "# relations = batch[5].squeeze().numpy()\n",
    "# relations\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# plot scatter plot\n",
    "# x = relations[1:, 0]\n",
    "# y = relations[1:, 1]\n",
    "# plt.scatter(x, y, s=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-15 00:58:52,233] [    INFO]\u001b[0m - Already cached /home/kaihong/.paddlenlp/models/bert-base-chinese/bert-base-chinese.pdparams\u001b[0m\n",
      "W1215 00:58:52.234423 1370870 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.0, Runtime API Version: 11.6\n",
      "W1215 00:58:52.236507 1370870 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\n",
      "\u001b[32m[2022-12-15 00:58:55,379] [    INFO]\u001b[0m - Weights from pretrained model not used in BertModel: ['cls.predictions.decoder_weight', 'cls.predictions.decoder_bias', 'cls.predictions.transform.weight', 'cls.predictions.transform.bias', 'cls.predictions.layer_norm.weight', 'cls.predictions.layer_norm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ppocr.modeling.architectures import build_model\n",
    "from ppocr.modeling.backbones import build_backbone\n",
    "\n",
    "config = {\n",
    "    'model_type': 'kie',\n",
    "    'Transform': None,\n",
    "    'Backbone': {\n",
    "        'name': 'BertForRe',\n",
    "        'pretrained': True,\n",
    "        'mode': 'base',\n",
    "        'checkpoint': None\n",
    "    }\n",
    "}\n",
    "\n",
    "model = build_model(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1215 00:59:05.578862 1370870 gpu_resources.cc:201] WARNING: device: \u0000. The installed Paddle is compiled with CUDNN 8.4, but CUDNN version in your machine is 8.1, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of preds: <class 'dict'>\n",
      "len of preds: 2\n",
      "type of preds: <class 'dict'>\n",
      "keys of preds: dict_keys(['loss', 'pred_relations'])\n"
     ]
    }
   ],
   "source": [
    "preds = model(batch)\n",
    "\n",
    "print(f\"type of preds: {type(preds)}\")\n",
    "print(f\"len of preds: {len(preds)}\")\n",
    "print(f\"type of preds: {type(preds)}\")\n",
    "print(f\"keys of preds: {preds.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of post_result: 3\n",
      "type of post_result: <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "from ppocr.postprocess import build_post_process\n",
    "\n",
    "config = {\n",
    "    \"name\": \"VQAReTokenLayoutLMPostProcess\",\n",
    "}\n",
    "\n",
    "batch_numpy = [out.numpy() for out in batch]\n",
    "post_process_class = build_post_process(config, global_config)\n",
    "post_result = post_process_class(preds, batch_numpy)\n",
    "print(f\"len of post_result: {len(post_result)}\")\n",
    "print(f\"type of post_result: {type(post_result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0, 'recall': 0, 'hmean': 0}\n"
     ]
    }
   ],
   "source": [
    "from ppocr.metrics import build_metric\n",
    "\n",
    "config = {\n",
    "    \"name\": \"VQAReTokenMetric\",\n",
    "    \"main_indicator\": \"hmean\",\n",
    "}\n",
    "\n",
    "eval_class = build_metric(config)\n",
    "eval_class(post_result, batch)\n",
    "metric = eval_class.get_metric()\n",
    "print(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "074329d52fc9efe72706b024b6721c6dc35ca1ef98bf3876eecafc902268d71c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
