{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "Global:\n",
    "\n",
    "Train:\n",
    "  dataset:\n",
    "    transforms:\n",
    "      - DecodeImage: # load image\n",
    "          img_mode: RGB\n",
    "          channel_first: False\n",
    "      - VQATokenLabelEncode: # Class handling label\n",
    "          contains_re: False\n",
    "          algorithm: Bert\n",
    "          class_path: train_data/XFUND/class_list_xfun.txt\n",
    "          use_textline_bbox_info: True\n",
    "          order_method: \"tb-yx\" # one of [None, \"tb-yx\"]\n",
    "      - VQATokenPad:\n",
    "          max_seq_len: 512\n",
    "          return_attention_mask: True\n",
    "      - VQASerTokenChunk:\n",
    "          max_seq_len: 512\n",
    "      - Resize:\n",
    "          size: [224,224]\n",
    "      - NormalizeImage:\n",
    "          scale: 1\n",
    "          mean: [ 123.675, 116.28, 103.53 ]\n",
    "          std: [ 58.395, 57.12, 57.375 ]\n",
    "          order: 'hwc'\n",
    "      - ToCHWImage:\n",
    "      - KeepKeys:\n",
    "          keep_keys: [ 'input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'image', 'labels'] # dataloader will return list in this order\n",
    "\"\"\"\n",
    "\n",
    "import yaml\n",
    "\n",
    "config = yaml.load(config, Loader=yaml.FullLoader)\n",
    "dataset_config = config['Train']['dataset']\n",
    "global_config = config['Global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-15 00:35:59,926] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.bert.tokenizer.BertTokenizer'> to load 'bert-base-chinese'.\u001b[0m\n",
      "\u001b[32m[2022-12-15 00:35:59,927] [    INFO]\u001b[0m - Already cached /home/kaihong/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-12-15 00:35:59,935] [    INFO]\u001b[0m - tokenizer config file saved in /home/kaihong/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-12-15 00:35:59,936] [    INFO]\u001b[0m - Special tokens file saved in /home/kaihong/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from ppocr.data.imaug import create_operators, transform\n",
    "import paddle\n",
    "\n",
    "data_dir = \"train_data/XFUND/zh_train/image\"\n",
    "label_file = \"train_data/XFUND/zh_train/train.json\"\n",
    "with open(label_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "line = lines[1].strip()\n",
    "file_name, label = line.split('\\t')\n",
    "img_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "data = {'img_path': img_path, 'label': label}\n",
    "with open(data['img_path'], 'rb') as f:\n",
    "    img = f.read()\n",
    "    data['image'] = img\n",
    "\n",
    "ops = create_operators(dataset_config['transforms'], global_config)\n",
    "\n",
    "outs = transform(data, ops)\n",
    "outs = [paddle.to_tensor(out, place='cpu') for out in outs]\n",
    "batch = [paddle.unsqueeze(out, axis=0) for out in outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of outs: <class 'list'>\n",
      "len of outs: 6\n",
      "shape of input_ids: [1, 512]\n",
      "shape of bbox: [1, 512, 4]\n",
      "shape of attention_mask: [1, 512]\n",
      "shape of token_type_ids: [1, 512]\n",
      "shape of image: [1, 3, 224, 224]\n",
      "shape of labels: [1, 512]\n"
     ]
    }
   ],
   "source": [
    "print(f\"type of outs: {type(batch)}\")\n",
    "print(f\"len of outs: {len(batch)}\")\n",
    "# keep_keys: [ 'input_ids', 'bbox', 'attention_mask',\n",
    "# 'token_type_ids', 'image', 'labels']\n",
    "print(f\"shape of input_ids: {batch[0].shape}\")\n",
    "print(f\"shape of bbox: {batch[1].shape}\")\n",
    "print(f\"shape of attention_mask: {batch[2].shape}\")\n",
    "print(f\"shape of token_type_ids: {batch[3].shape}\")\n",
    "print(f\"shape of image: {batch[4].shape}\")\n",
    "print(f\"shape of labels: {batch[5].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from paddlenlp.transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"layoutxlm-base-uncased\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "# input_ids = batch[0][0].numpy().tolist()\n",
    "# print(tokenizer.decode(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-12-15 00:35:47,782] [    INFO]\u001b[0m - Already cached /home/kaihong/.paddlenlp/models/bert-base-chinese/bert-base-chinese.pdparams\u001b[0m\n",
      "W1215 00:35:47.783761 1354768 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.0, Runtime API Version: 11.6\n",
      "W1215 00:35:47.785861 1354768 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.\n",
      "\u001b[32m[2022-12-15 00:35:50,916] [    INFO]\u001b[0m - Weights from pretrained model not used in BertModel: ['cls.predictions.decoder_weight', 'cls.predictions.decoder_bias', 'cls.predictions.transform.weight', 'cls.predictions.transform.bias', 'cls.predictions.layer_norm.weight', 'cls.predictions.layer_norm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ppocr.modeling.architectures import build_model\n",
    "from ppocr.modeling.backbones import build_backbone\n",
    "\n",
    "config = {\n",
    "    'model_type': 'kie',\n",
    "    'Transform': None,\n",
    "    'Backbone': {\n",
    "        'name': 'BertForSer',\n",
    "        'pretrained': True,\n",
    "        'checkpoints': None,\n",
    "        'mode': 'base',\n",
    "        'num_classes': 7\n",
    "    }\n",
    "}\n",
    "\n",
    "model = build_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1215 00:36:04.388424 1354768 gpu_resources.cc:201] WARNING: device: \u0000. The installed Paddle is compiled with CUDNN 8.4, but CUDNN version in your machine is 8.1, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of preds: <class 'dict'>\n",
      "len of preds: 1\n",
      "type of preds: <class 'dict'>\n",
      "shape of preds['backbone_out']: [1, 512, 7]\n"
     ]
    }
   ],
   "source": [
    "preds = model(batch)\n",
    "\n",
    "print(f\"type of preds: {type(preds)}\")\n",
    "print(f\"len of preds: {len(preds)}\")\n",
    "print(f\"type of preds: {type(preds)}\")\n",
    "print(f\"shape of preds['backbone_out']: {preds['backbone_out'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppocr.postprocess import build_post_process\n",
    "\n",
    "config = {\n",
    "    \"name\": \"VQASerTokenLayoutLMPostProcess\",\n",
    "    \"class_path\": \"train_data/XFUND/class_list_xfun.txt\"\n",
    "}\n",
    "\n",
    "batch_numpy = [out.numpy() for out in batch]\n",
    "post_process_class = build_post_process(config, global_config)\n",
    "post_result = post_process_class(preds['backbone_out'], batch_numpy)\n",
    "print(f\"len of post_result: {len(post_result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppocr.metrics import build_metric\n",
    "\n",
    "config = {\n",
    "    \"name\": \"VQASerTokenMetric\",\n",
    "    \"main_indicator\": \"hmean\",\n",
    "}\n",
    "\n",
    "eval_class = build_metric(config)\n",
    "eval_class(post_result, batch)\n",
    "metric = eval_class.get_metric()\n",
    "print(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daa63b9d19f3656d73becf61cadaa6df43f328a8f4816d4c0eb7f807365bdcd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
